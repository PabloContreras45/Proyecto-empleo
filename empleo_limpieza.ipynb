{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entramos al apartado de limpieza y preparación de SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.11/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /opt/anaconda3/lib/python3.11/site-packages (5.9.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from plotly) (8.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/python3\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: scikit-learn 1.5.2\n",
      "Uninstalling scikit-learn-1.5.2:\n",
      "  Would remove:\n",
      "    /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scikit_learn-1.5.2.dist-info/*\n",
      "    /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/*\n",
      "Proceed (Y/n)? ^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (2.0.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping plotly as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (5.24.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from plotly) (9.0.0)\n",
      "Requirement already satisfied: packaging in /Users/pablo/Library/Python/3.12/lib/python/site-packages (from plotly) (24.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nbformat\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat)\n",
      "  Using cached fastjsonschema-2.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting jsonschema>=2.6 (from nbformat)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/pablo/Library/Python/3.12/lib/python/site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in /Users/pablo/Library/Python/3.12/lib/python/site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat) (24.2.0)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=2.6->nbformat)\n",
      "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=2.6->nbformat)\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=2.6->nbformat)\n",
      "  Using cached rpds_py-0.20.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/pablo/Library/Python/3.12/lib/python/site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat) (4.2.2)\n",
      "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Using cached fastjsonschema-2.20.0-py3-none-any.whl (23 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached referencing-0.35.1-py3-none-any.whl (26 kB)\n",
      "Using cached rpds_py-0.20.0-cp312-cp312-macosx_11_0_arm64.whl (313 kB)\n",
      "Installing collected packages: fastjsonschema, rpds-py, referencing, jsonschema-specifications, jsonschema, nbformat\n",
      "Successfully installed fastjsonschema-2.20.0 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 nbformat-5.10.4 referencing-0.35.1 rpds-py-0.20.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                       Título Ubicación  \\\n",
      "0           0                                 Data Analyst    Madrid   \n",
      "1           1  Business Intelligence Analyst (all genders)    Madrid   \n",
      "2           2   Research Analyst (6 month Maternity Cover)    Madrid   \n",
      "3           3    Senior Program Manager, Analyst Relations    Madrid   \n",
      "4           4                       [RJ072] | Data Analyst    Madrid   \n",
      "\n",
      "                                         Descripción  \\\n",
      "0  Una empresa internacional y dinámica busca un ...   \n",
      "1  An innovative edtech company is seeking a Busi...   \n",
      "2  An established industry player is seeking a Re...   \n",
      "3  Join a forward-thinking company at the forefro...   \n",
      "4  Join a forward-thinking company as a Data Anal...   \n",
      "\n",
      "                                           Servicios               Sueldo  \\\n",
      "0  ['Tarjeta de restauranteSeguro de saludSeguro ...  EUR 50,000 - 70,000   \n",
      "1  ['Flexible hybrid work environmentComprehensiv...  EUR 50,000 - 70,000   \n",
      "2  ['Competitive benefitsCareer development oppor...  EUR 30,000 - 50,000   \n",
      "3  ['Equity (Restricted Stock Units)Life Insuranc...  EUR 50,000 - 70,000   \n",
      "4  ['Flexible working hoursHealth insuranceLife i...  EUR 50,000 - 70,000   \n",
      "\n",
      "                    Timestamp  \\\n",
      "0  2024-10-31 11:15:55.927390   \n",
      "1  2024-10-31 11:15:56.598105   \n",
      "2  2024-10-31 11:15:57.508127   \n",
      "3  2024-10-31 11:15:58.398931   \n",
      "4  2024-10-31 11:15:59.317859   \n",
      "\n",
      "                                                 Url  \n",
      "0  https://jobleads.com/job/eba2bf38bdc4c66ba2f5f...  \n",
      "1  https://jobleads.com/job/e4b1388ab13374dab4103...  \n",
      "2  https://jobleads.com/job/ec2be137e14f9dbc1a8eb...  \n",
      "3  https://jobleads.com/job/ea5922eccaee3331c3aba...  \n",
      "4  https://jobleads.com/job/ea6ecb7b732973b55d2da...  \n",
      "Otro Idioma\n",
      "Inglés     21\n",
      "Francés     6\n",
      "Name: count, dtype: int64\n",
      "Ubicación\n",
      "Cataluña     525\n",
      "Madrid       514\n",
      "Andalucía      4\n",
      "Name: count, dtype: int64\n",
      "Empresa\n",
      "Santander    13\n",
      "VIE           4\n",
      "Amazon        2\n",
      "BCG           2\n",
      "Mckinsey      2\n",
      "Microsoft     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, StaleElementReferenceException\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "import requests\n",
    "import sqlite3\n",
    "import re\n",
    "from sklearn.cluster import KMeans\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import nbformat\n",
    "# Lee el archivo CSV\n",
    "df = pd.read_csv('portales_empleo.csv')\n",
    "\n",
    "# Muestra las primeras filas del DataFrame\n",
    "print(df.head())\n",
    "\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "# Eliminar filas duplicadas en su totalidad\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "\n",
    "def limpieza_salario(rango_salarios):\n",
    "    # Eliminar 'EUR' y comas\n",
    "    rango_salarios = rango_salarios.replace('EUR', '').replace(',', '').strip()\n",
    "    \n",
    "    # Separar en salario mínimo y máximo\n",
    "    if ' - ' in rango_salarios:\n",
    "        rango = rango_salarios.split(' - ')\n",
    "        salario_min = int(rango[0].strip())\n",
    "        salario_max = int(rango[1].strip())\n",
    "    else:\n",
    "        # Si no hay rango, usar el valor como salario mínimo y máximo\n",
    "        salario_min = salario_max = int(rango_salarios)\n",
    "\n",
    "    return salario_min, salario_max\n",
    "\n",
    "# Aplicar la función al DataFrame\n",
    "df['sueldo_min'], df['sueldo_max'] = zip(*df['Sueldo'].map(limpieza_salario))\n",
    "\n",
    "# Elimina el texto entre paréntesis en la columna 'título'\n",
    "df['Título'] = df['Título'].str.replace(r'\\(.*?\\)', '', regex=True)\n",
    "\n",
    "# Elimina los signos '|' y '/'\n",
    "df['Título'] = df['Título'].str.replace(r'[|/]', '', regex=True)\n",
    "\n",
    "# Elimina espacios en blanco adicionales\n",
    "df['Título'] = df['Título'].str.strip()\n",
    "\n",
    "# Elimina el texto entre corchetes en la columna 'título'\n",
    "df['Título'] = df['Título'].str.replace(r'\\[.*?\\]', '', regex=True)\n",
    "\n",
    "# Elimina los signos '|', '/' y '-'\n",
    "df['Título'] = df['Título'].str.replace(r'[|/-]', '', regex=True)\n",
    "\n",
    "# Elimina espacios en blanco adicionales\n",
    "df['Título'] = df['Título'].str.strip()\n",
    "\n",
    "# Muestra las primeras filas del DataFrame\n",
    "df.head(5)\n",
    "# Función para actualizar títulos\n",
    "def actualizar_titulo(titulo):\n",
    "    # Reemplazar 'jr' por 'Junior' y 'sr' por 'Senior'\n",
    "    titulo = titulo.replace(' jr ', ' Junior ').replace(' sr ', ' Senior ')\n",
    "    titulo = titulo.replace('jr ', 'Junior ').replace('sr ', 'Senior ')\n",
    "    titulo = titulo.replace(' jr', ' Junior').replace(' sr', ' Senior')\n",
    "    return titulo\n",
    "\n",
    "# Aplicar la función de actualización a la columna 'Título'\n",
    "df['Título'] = df['Título'].apply(actualizar_titulo)\n",
    "def get_expertise(title):\n",
    "    if 'Senior' in title or 'senior' in title or 'master' in title or 'manager' in title:\n",
    "        return 'Senior'\n",
    "    elif 'Junior' in title or 'junior' in title:\n",
    "        return 'Junior'\n",
    "    elif 'intern' in title or 'becario' in title:\n",
    "        return 'Intern'\n",
    "    elif 'Lead' in title or 'lead' in title:\n",
    "        return 'Lead' \n",
    "    else:\n",
    "        return 'Regular'\n",
    "\n",
    "# Crear la nueva columna \"Expertise\" aplicando la función sobre la columna \"Título\"\n",
    "df['Expertise'] = df['Título'].apply(get_expertise)\n",
    "import re\n",
    "# Listas de palabras clave (nombres de empresas y sectores)\n",
    "empresas = ['santander', 'amazon', 'microsoft', 'vie', 'bcg', 'mckinsey']  # Añadir más nombres de empresas\n",
    "sectores = ['marketing', 'medtech', 'fintech', 'ecommerce', 'finance', 'game','genai','digital', 'tax', 'governance', 'energy' ]  # Añadir más sectores\n",
    "\n",
    "# Convertir las listas a un conjunto de expresiones regulares para facilitar la búsqueda\n",
    "regex_empresas = re.compile(r'\\b(' + '|'.join(empresas) + r')\\b', re.IGNORECASE)\n",
    "regex_sectores = re.compile(r'\\b(' + '|'.join(sectores) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "# Función para extraer empresa\n",
    "def extraer_empresa(titulo):\n",
    "    match = regex_empresas.search(titulo)\n",
    "    return match.group(0) if match else None\n",
    "\n",
    "# Función para extraer sector\n",
    "def extraer_sector(titulo):\n",
    "    match = regex_sectores.search(titulo)\n",
    "    return match.group(0) if match else None\n",
    "\n",
    "# Función para limpiar el título\n",
    "def limpiar_titulo(titulo):\n",
    "    # Eliminar nombres de empresas y sectores del título\n",
    "    titulo = regex_empresas.sub('', titulo)\n",
    "    titulo = regex_sectores.sub('', titulo)\n",
    "    # Eliminar espacios extra\n",
    "    return ' '.join(titulo.split())\n",
    "\n",
    "# Aplicar las funciones a las columnas del DataFrame\n",
    "df['Empresa'] = df['Título'].apply(extraer_empresa)\n",
    "df['Sector'] = df['Título'].apply(extraer_sector)\n",
    "df['Título'] = df['Título'].apply(limpiar_titulo)\n",
    "df.head(12)\n",
    "# Detecta la palabra clave \"Inglés\" y asigna a la nueva columna 'Otro Idioma'\n",
    "df['Otro Idioma'] = df['Título'].apply(lambda x: 'inglés' if 'inglés' in x else None)\n",
    "\n",
    "# Detecta la palabra clave \"Inglés\" y asigna a la nueva columna 'Otro Idioma'\n",
    "df['Otro Idioma'] = df['Título'].apply(lambda x: 'English' if 'English' in x else None)\n",
    "\n",
    "# Detecta las palabras clave \"Híbrido\", \"Remoto\" o \"Presencial\" y asigna a la nueva columna 'Modalidad'\n",
    "df['Modalidad'] = df['Título'].apply(lambda x: 'Híbrido' if 'Híbrido' in x else ('Remoto' if 'Remoto' in x else ('Presencial' if 'Presencial' in x else None)))\n",
    "\n",
    "df['Otro Idioma'] = df['Título'].apply(lambda x: 'english' if 'english' in x else None)\n",
    "df['Otro Idioma'] = df['Título'].apply(lambda x: 'french' if 'french' in x else None)\n",
    "df['Otro Idioma'] = df['Título'].apply(lambda x: 'francés' if 'francés' in x else None)\n",
    "# Función para detectar los idiomas\n",
    "def detectar_idiomas(titulo):\n",
    "    if 'inglés' in titulo.lower() or 'english' in titulo.lower():\n",
    "        return 'Inglés'\n",
    "    elif 'francés' in titulo.lower() or 'french' in titulo.lower():\n",
    "        return 'Francés'\n",
    "    # Puedes añadir más idiomas aquí\n",
    "    return None\n",
    "\n",
    "# Aplicar la función para detectar idiomas\n",
    "df['Otro Idioma'] = df['Título'].apply(detectar_idiomas)\n",
    "titulos_agrupados = df['Otro Idioma'].value_counts()\n",
    "print(titulos_agrupados)\n",
    "# Diccionario de ubicaciones y sus modificaciones\n",
    "ubicaciones_dict = {\n",
    "    'Boadilla del Monte': 'Madrid',\n",
    "    'Alcobendas': 'Madrid',\n",
    "    'Leganés': 'Madrid',\n",
    "    'Getafe': 'Madrid',\n",
    "    'Barcelona, Centro': 'Cataluña',\n",
    "    'Esplugues de Llobregat': 'Cataluña',\n",
    "    'Barcelona': 'Cataluña',\n",
    "    'Pozuelo de Alarcón': 'Madrid',\n",
    "    'Tres Cantos': 'Madrid',\n",
    "    'Villaviciosa de Odón': 'Madrid',\n",
    "    'Sant Just Desvern': 'Cataluña',\n",
    "    'Sant Cugat del Vallès':'Cataluña'\n",
    "}\n",
    "\n",
    "# Función para reemplazar la ubicación según el diccionario\n",
    "df['Ubicación'] = df['Ubicación'].replace(ubicaciones_dict)\n",
    "titulos_agrupados = df['Ubicación'].value_counts()\n",
    "print(titulos_agrupados)\n",
    "titulos_agrupados = df['Empresa'].value_counts()\n",
    "print(titulos_agrupados)\n",
    "# Remover caracteres innecesarios y estandarizar\n",
    "df['Título'] = df['Título'].str.replace(r'[^\\w\\s]', '', regex=True).str.strip().str.lower()\n",
    "# Crear columna de 'Puesto' principal basado en palabras clave\n",
    "def clasificar_rol(titulo):\n",
    "    if 'data scientist' in titulo:\n",
    "        return 'Data Scientist'\n",
    "    elif 'data applied scientist ii at barcelona spain' in titulo:\n",
    "        return 'Data Scientist'\n",
    "    elif 'data engineer' in titulo:\n",
    "        return 'Data Engineer'\n",
    "    elif 'analyst' in titulo:\n",
    "        return 'Data Analyst'\n",
    "    elif 'machine learning' in titulo:\n",
    "        return 'Machine Learning Engineer'\n",
    "    elif 'business intelligence' in titulo:\n",
    "        return 'Business Intelligence'\n",
    "    elif 'consultant' in titulo:\n",
    "        return 'Consultant'\n",
    "    elif 'specialist' in titulo:\n",
    "        return 'Data Specialist'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "df['Puesto'] = df['Título'].apply(clasificar_rol)\n",
    "# Reordenar columnas en el orden especificado\n",
    "columnas_ordenadas = [\n",
    "    'Título', 'Puesto', 'sueldo_min','sueldo_max','Expertise', 'Empresa', 'Modalidad', 'Sector', \n",
    "    'Ubicación', 'Descripción', 'Servicios', 'Otro Idioma'\n",
    "]\n",
    "df = df[columnas_ordenadas]\n",
    "# Función para clasificar el puesto basado en palabras clave extendidas\n",
    "def clasificar_rol(titulo):\n",
    "    titulo = titulo.lower()\n",
    "    if 'data scientist' in titulo:\n",
    "        return 'Data Scientist'\n",
    "    elif 'data applied scientist ii at barcelona spain' in titulo:\n",
    "        return 'Data Scientist'\n",
    "    elif 'data engineer' in titulo:\n",
    "        return 'Data Engineer'\n",
    "    elif 'data manager' in titulo or 'manager data' in titulo:\n",
    "        return 'Data Manager'\n",
    "    elif 'head of data' in titulo:\n",
    "        return 'Data Manager'\n",
    "    elif 'data expert' in titulo:\n",
    "        return 'Data Expert'\n",
    "    elif 'big data architect' in titulo:\n",
    "        return 'Big Data Architect'\n",
    "    elif 'manager data cloud' in titulo:\n",
    "        return 'Data Manager Cloud'\n",
    "    elif 'data analytics' in titulo:\n",
    "        return 'Data Analytics'\n",
    "    elif 'ai innovation architect' in titulo:\n",
    "        return 'AI Innovation Architect'\n",
    "    elif 'data management engineer' in titulo:\n",
    "        return 'Data Manager'\n",
    "    elif 'business intelligence' in titulo:\n",
    "        return 'Business Intelligence'\n",
    "    elif 'analyst' in titulo:\n",
    "        return 'Data Analyst'\n",
    "    elif 'consultant' in titulo:\n",
    "        return 'Consultant'\n",
    "    elif 'machine learning' in titulo:\n",
    "        return 'Machine Learning Engineer'\n",
    "    elif 'specialist' in titulo:\n",
    "        return 'Data Specialist'\n",
    "    elif 'data developer' in titulo:\n",
    "        return 'Data Developer'\n",
    "    elif 'project manager' in titulo:\n",
    "        return 'Project Manager'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Aplicar la función a la columna \"Título\" para crear o actualizar la columna \"Puesto\"\n",
    "df['Puesto'] = df['Título'].apply(clasificar_rol)\n",
    "\n",
    "# Función para limpiar nombres de ciudades y códigos de puesto directamente en \"Título\"\n",
    "def limpiar_titulo(titulo):\n",
    "    # Eliminación de nombres de ciudades comunes en títulos\n",
    "    ciudades = [\"barcelone\", \"alicante\", \"catalonia\", \"madrid\", \"bilbao\"]  # Añadir otras ciudades según sea necesario\n",
    "    for ciudad in ciudades:\n",
    "        titulo = re.sub(rf\"\\b{ciudad}\\b\", \"\", titulo, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Eliminación de códigos de puesto que suelen ser letras y números juntos\n",
    "    titulo = re.sub(r\"\\b[a-zA-Z]{2,3}\\d{3}\\b\", \"\", titulo)\n",
    "    \n",
    "    # Eliminación de espacios extras generados por las sustituciones\n",
    "    titulo = re.sub(r\"\\s+\", \" \", titulo).strip()\n",
    "    return titulo\n",
    "\n",
    "# Aplicar la función de limpieza a la columna \"Título\" para modificarla directamente\n",
    "df['Título'] = df['Título'].apply(limpiar_titulo)\n",
    "\n",
    "# Función para extraer herramientas tecnológicas\n",
    "def extraer_herramientas(titulo):\n",
    "    herramientas = [\"Salesforce\", \"CRM\", \"Power BI\", \"Qlik\", \"Python\", \"Tableau\", \"SAS\", \"SAP\", \"BigQuery\", \"Datastage\", \"Analytics\", \"Pentaho\", \"Spark\"]  # Añadir otras herramientas según sea necesario\n",
    "    herramientas_encontradas = [herramienta for herramienta in herramientas if herramienta.lower() in titulo.lower()]\n",
    "    return \", \".join(herramientas_encontradas) if herramientas_encontradas else None\n",
    "\n",
    "# Crear la columna \"Herramientas\" con las herramientas tecnológicas encontradas en el título\n",
    "df['EntornoTEC'] = df['Título'].apply(extraer_herramientas)\n",
    "def convertir_abreviaciones(titulo):\n",
    "    titulo = titulo.lower()  # Convertir a minúsculas para comparación\n",
    "    if 'sr' in titulo:\n",
    "        titulo = titulo.replace('sr', 'senior')\n",
    "    if 'jr' in titulo:\n",
    "        titulo = titulo.replace('jr', 'junior')\n",
    "    return titulo\n",
    "\n",
    "# Aplicar la función para convertir los títulos\n",
    "df['Título'] = df['Título'].apply(convertir_abreviaciones)\n",
    "def get_expertise(title):\n",
    "    if 'Senior' in title or 'senior' in title or 'master' in title or 'manager' in title:\n",
    "        return 'Senior'\n",
    "    elif 'Junior' in title or 'junior' in title or 'associate' in title:\n",
    "        return 'Junior'\n",
    "    elif 'intern' in title or 'becario' in title or 'becarioa' in title:\n",
    "        return 'Intern'\n",
    "    elif 'Lead' in title or 'lead' in title or 'head' in title:\n",
    "        return 'Lead' \n",
    "    else:\n",
    "        return 'Regular'\n",
    "\n",
    "# Crear la nueva columna \"Expertise\" aplicando la función sobre la columna \"Título\"\n",
    "df['Expertise'] = df['Título'].apply(get_expertise)\n",
    "titulos_agrupados = df['Puesto'].value_counts()\n",
    "# Filtrar filas que contengan el texto deseado en la columna \"Título\"\n",
    "filtro = df[df['Puesto'].str.contains(\"Other\", case=False, na=False)]\n",
    "\n",
    "# Función para agregar espacios entre palabras correctamente\n",
    "def add_spaces(text):\n",
    "    # Añade un espacio entre palabras que estén pegadas (ej: \"SnacksWeekly\" -> \"Snacks Weekly\")\n",
    "    corrected_text = re.sub(r'(?<=[a-zA-Z])(?=[A-Z])', ' ', text)\n",
    "    return corrected_text\n",
    "\n",
    "# Aplicar la función a la columna \"Servicios\"\n",
    "df['Servicios'] = df['Servicios'].apply(add_spaces)\n",
    "# Lista de palabras comunes a eliminar\n",
    "common_words = r'\\b(de|a|in|or|and|the|of|en|con|para|por|y|del|la|los|las|un|una)\\b'\n",
    "\n",
    "# Definición de las palabras clave para cada categoría\n",
    "benefits_keywords = r'\\b(Tarjeta de restaurante|Teletrabajo opcional|Flexible hours|Modern office environment|Continuous learning programs|Mentoring programs|Collaborative culture|Oportunidades de crecimiento profesional|Paquete competitivo de compensación y beneficios|Retirement program|Well-being programs|Diversity initiatives|Work-life balance|Remote work)\\b'\n",
    "skills_keywords = r'\\b(Neural networks|Bayesian modeling|Data storytelling|Análisis de datos|Métodos estadísticos|Business Intelligence|Data Science|Machine Learning|Deep Learning|Data Visualization|Problem Solving|Data Analysis|Reporting|Data governance|Statistical Analysis|Predictive Modeling)\\b'\n",
    "tools_keywords = r'\\b(Python|R|Pyspark|Power BI|Tableau|Databricks|GCP|SAS|SQL|Excel|VBA|Google Analytics|Adobe Analytics|Domo|Snowflake|TensorFlow|Keras|Scikit-learn|Power Platforms|Jupyter Notebooks|Azure|AWS|Docker|GitHub|Streamlit|Pytorch|BigQuery|SQL)\\b'\n",
    "education_keywords = r'\\b(Degree in Computing or Statistics|Bachelor\\'s Degree|Master\\'s Degree|PhD|Licenciatura|Grado|Engineering Degree|Data Science Degree|Statistics Degree|Computer Science Degree|Mathematics Degree)\\b'\n",
    "\n",
    "# Función para limpiar texto de palabras comunes\n",
    "def remove_common_words(text):\n",
    "    return re.sub(common_words, '', text, flags=re.IGNORECASE)\n",
    "\n",
    "# Función para clasificar las palabras en las categorías\n",
    "def classify_services(services):\n",
    "    # Limpiar palabras comunes\n",
    "    services_cleaned = remove_common_words(services)\n",
    "    \n",
    "    # Clasificar términos en categorías\n",
    "    benefits = re.findall(benefits_keywords, services_cleaned, flags=re.IGNORECASE)\n",
    "    skills = re.findall(skills_keywords, services_cleaned, flags=re.IGNORECASE)\n",
    "    tools = re.findall(tools_keywords, services_cleaned, flags=re.IGNORECASE)\n",
    "    education = re.findall(education_keywords, services_cleaned, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Devolver resultados en columnas separadas\n",
    "    return pd.Series({\n",
    "        'Beneficios': ', '.join(benefits) if benefits else None,\n",
    "        'Habilidades': ', '.join(skills) if skills else None,\n",
    "        'Herramientas': ', '.join(tools) if tools else None,\n",
    "        'Educación': ', '.join(education) if education else None,\n",
    "    })\n",
    "\n",
    "# Aplicar la función a cada fila\n",
    "df_new = df['Servicios'].apply(classify_services)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                    None\n",
       "1                      Análisis de datos, Data governance\n",
       "2               Análisis de datos, Visualización de datos\n",
       "3                                                    None\n",
       "4               Análisis de datos, Visualización de datos\n",
       "                              ...                        \n",
       "1038                  Análisis de datos, Machine learning\n",
       "1039    Análisis de datos, Machine learning, Visualiza...\n",
       "1040                                                 None\n",
       "1041                                                 None\n",
       "1042                                                 None\n",
       "Name: Habilidades, Length: 1043, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['Habilidades']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de mapeo para estandarizar las respuestas de habilidades\n",
    "skills_mapping = {\n",
    "    r'\\b(data analysis|análisis de datos|data science)\\b': 'Análisis de datos',\n",
    "    r'\\b(machine learning|aprendizaje automático)\\b': 'Machine Learning',\n",
    "    r'\\b(deep learning|aprendizaje profundo)\\b': 'Deep Learning',\n",
    "    r'\\b(data visualization|visualización de datos)\\b': 'Visualización de datos',\n",
    "    r'\\b(statistical analysis|análisis estadístico)\\b': 'Análisis estadístico',\n",
    "    r'\\b(predictive modeling|modelado predictivo)\\b': 'Modelado predictivo',\n",
    "    r'\\b(business intelligence|bi)\\b': 'Business Intelligence',\n",
    "    r'\\b(reporting|reportes)\\b': 'Reporting',\n",
    "    r'\\b(agile methodologies|metodologías ágiles)\\b': 'Metodologías Ágiles',\n",
    "    r'\\b(optimización|optimization)\\b': 'Optimización',\n",
    "    r'\\b(excel avanzado)\\b': 'Excel Avanzado',\n",
    "    r'\\b(habilidades analíticas|analytical skills)\\b': 'Habilidades analíticas',\n",
    "    r'\\b(problem solving|resolución de problemas)\\b': 'Resolución de problemas',\n",
    "    r'\\b(neural networks|redes neuronales)\\b': 'Redes Neuronales'\n",
    "}\n",
    "\n",
    "# Función para estandarizar la columna de habilidades\n",
    "def standardize_skills(text):\n",
    "    # Verificar si el texto es None antes de proceder\n",
    "    if text is None:\n",
    "        return None\n",
    "    \n",
    "    # Normalizar cada habilidad según el mapeo\n",
    "    for pattern, standard_skill in skills_mapping.items():\n",
    "        text = re.sub(pattern, standard_skill, text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Convertir en lista, eliminar duplicados y ordenar\n",
    "    skills_list = list(set(text.split(',')))\n",
    "    skills_list = sorted([skill.strip().capitalize() for skill in skills_list if skill.strip()])\n",
    "    \n",
    "    # Unir la lista en una sola cadena de texto\n",
    "    return ', '.join(skills_list)\n",
    "\n",
    "df_new['Habilidades'] = df_new['Habilidades'].apply(standardize_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "titulos_agrupados = df_new['Habilidades'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Habilidades\n",
       "Análisis de datos                                                                                         63\n",
       "Machine learning                                                                                          32\n",
       "Análisis de datos, Visualización de datos                                                                 21\n",
       "Análisis de datos, Machine learning                                                                       15\n",
       "Análisis de datos, Machine learning, Visualización de datos                                               13\n",
       "                                                                                                          ..\n",
       "Business intelligence, Machine learning                                                                    1\n",
       "Análisis de datos, Análisis estadístico, Machine learning, Modelado predictivo, Visualización de datos     1\n",
       "Análisis de datos, Análisis de datos, Deep learning, Machine learning, Visualización de datos              1\n",
       "Análisis de datos, Análisis de datos, Reporting                                                            1\n",
       "Análisis de datos, Deep learning, Machine learning, Machine learning                                       1\n",
       "Name: count, Length: 77, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titulos_agrupados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            Licenciatura\n",
      "1       Bachelor's degree\n",
      "2                    None\n",
      "3       Bachelor's degree\n",
      "4       Bachelor's degree\n",
      "              ...        \n",
      "1038                 None\n",
      "1039      Master's degree\n",
      "1040                 None\n",
      "1041                 None\n",
      "1042                 None\n",
      "Name: Educación, Length: 1043, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Diccionario de mapeo para estandarizar las respuestas de educación\n",
    "education_mapping = {\n",
    "    r'\\b(grado)\\b': 'Grado',\n",
    "    r'\\b(licenciatura)\\b': 'Licenciatura',\n",
    "    r'\\b(engineering degree|ingeniería)\\b': 'Ingeniería',\n",
    "    r'\\b(computer science degree)\\b': 'Ciencias de la computación',\n",
    "    r'\\b(mathematics degree)\\b': 'Matemáticas',\n",
    "    r'\\b(statistics degree)\\b': 'Estadística',\n",
    "    r'\\b(ciencias económicas|economics)\\b': 'Ciencias económicas'\n",
    "}\n",
    "\n",
    "# Función para estandarizar la columna de educación\n",
    "def standardize_education(text):\n",
    "    # Verificar si el texto es None antes de proceder\n",
    "    if text is None:\n",
    "        return None\n",
    "    \n",
    "    # Normalizar cada grado según el mapeo\n",
    "    for pattern, standard_education in education_mapping.items():\n",
    "        text = re.sub(pattern, standard_education, text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Convertir en lista, eliminar duplicados y ordenar\n",
    "    education_list = list(set(text.lower().split(',')))  # Convertir a minúsculas para evitar duplicados por mayúsculas\n",
    "    education_list = sorted(set([edu.strip().capitalize() for edu in education_list if edu.strip()]))\n",
    "    \n",
    "    # Unir la lista en una sola cadena de texto\n",
    "    return ', '.join(education_list)\n",
    "\n",
    "# Aplicar la estandarización directamente a la columna \"Educación\"\n",
    "df_new['Educación'] = df_new['Educación'].apply(standardize_education)\n",
    "\n",
    "# Mostrar el DataFrame con la columna estandarizada\n",
    "print(df_new['Educación'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de mapeo para estandarizar las respuestas de herramientas\n",
    "tools_mapping = {\n",
    "    r'\\b(python)\\b': 'Python',\n",
    "    r'\\b(excel)\\b': 'Excel',\n",
    "    r'\\b(tableau)\\b': 'Tableau',\n",
    "    r'\\b(azure)\\b': 'Azure',\n",
    "    r'\\b(docker)\\b': 'Docker',\n",
    "    r'\\b(snowflake)\\b': 'Snowflake',\n",
    "    r'\\b(pyspark)\\b': 'PySpark',\n",
    "    r'\\b(scikit-learn|scikit learn)\\b': 'Scikit-learn',\n",
    "    r'\\b(databricks)\\b': 'Databricks',\n",
    "    r'\\b(google analytics)\\b': 'Google Analytics',\n",
    "    r'\\b(adobe analytics)\\b': 'Adobe Analytics',\n",
    "    r'\\b(power bi)\\b': 'Power BI',\n",
    "    r'\\b(github)\\b': 'GitHub',\n",
    "    r'\\b(tensorflow)\\b': 'TensorFlow',\n",
    "    r'\\b(keras)\\b': 'Keras',\n",
    "    r'\\b(pytorch)\\b': 'PyTorch',\n",
    "    r'\\b(jupyter notebooks)\\b': 'Jupyter Notebooks',\n",
    "    r'\\b(navision)\\b': 'Navision',\n",
    "    r'\\b(refinitiv eikon|eikon)\\b': 'Refinitiv Eikon',\n",
    "    r'\\b(bloomberg)\\b': 'Bloomberg',\n",
    "    r'\\b(streamlit)\\b': 'Streamlit'\n",
    "}\n",
    "\n",
    "# Función para estandarizar la columna de herramientas\n",
    "def standardize_tools(text):\n",
    "    # Verificar si el texto es None antes de proceder\n",
    "    if text is None:\n",
    "        return None\n",
    "    \n",
    "    # Normalizar cada herramienta según el mapeo\n",
    "    for pattern, standard_tool in tools_mapping.items():\n",
    "        text = re.sub(pattern, standard_tool, text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Convertir en lista, eliminar duplicados y ordenar\n",
    "    tools_list = list(set(text.lower().split(',')))  # Convertir a minúsculas para evitar duplicados por mayúsculas\n",
    "    tools_list = sorted(set([tool.strip().capitalize() for tool in tools_list if tool.strip()]))\n",
    "    \n",
    "    # Unir la lista en una sola cadena de texto\n",
    "    return ', '.join(tools_list)\n",
    "\n",
    "# Aplicar la estandarización directamente a la columna \"Herramientas\"\n",
    "df_new['Herramientas'] = df_new['Herramientas'].apply(standardize_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Excel, Python, R\n",
       "1                Tableau\n",
       "2         Excel, Tableau\n",
       "3                   None\n",
       "4       Excel, Python, R\n",
       "              ...       \n",
       "1038                None\n",
       "1039       Azure, Python\n",
       "1040                None\n",
       "1041                None\n",
       "1042                None\n",
       "Name: Herramientas, Length: 1043, dtype: object"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new['Herramientas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Título', 'Puesto', 'sueldo_min', 'sueldo_max', 'Expertise', 'Empresa',\n",
       "       'Modalidad', 'Sector', 'Ubicación', 'Descripción', 'Servicios',\n",
       "       'Otro Idioma', 'EntornoTEC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beneficios</th>\n",
       "      <th>Habilidades</th>\n",
       "      <th>Herramientas</th>\n",
       "      <th>Educación</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Excel, Python, R</td>\n",
       "      <td>Licenciatura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Análisis de datos, Data governance</td>\n",
       "      <td>Tableau</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>Análisis de datos, Visualización de datos</td>\n",
       "      <td>Excel, Tableau</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>Análisis de datos, Visualización de datos</td>\n",
       "      <td>Excel, Python, R</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>None</td>\n",
       "      <td>Análisis de datos, Machine learning</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>None</td>\n",
       "      <td>Análisis de datos, Machine learning, Visualiza...</td>\n",
       "      <td>Azure, Python</td>\n",
       "      <td>Master's degree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1043 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Beneficios                                        Habilidades  \\\n",
       "0          None                                               None   \n",
       "1          None                 Análisis de datos, Data governance   \n",
       "2          None          Análisis de datos, Visualización de datos   \n",
       "3          None                                               None   \n",
       "4          None          Análisis de datos, Visualización de datos   \n",
       "...         ...                                                ...   \n",
       "1038       None                Análisis de datos, Machine learning   \n",
       "1039       None  Análisis de datos, Machine learning, Visualiza...   \n",
       "1040       None                                               None   \n",
       "1041       None                                               None   \n",
       "1042       None                                               None   \n",
       "\n",
       "          Herramientas          Educación  \n",
       "0     Excel, Python, R       Licenciatura  \n",
       "1              Tableau  Bachelor's degree  \n",
       "2       Excel, Tableau               None  \n",
       "3                 None  Bachelor's degree  \n",
       "4     Excel, Python, R  Bachelor's degree  \n",
       "...                ...                ...  \n",
       "1038              None               None  \n",
       "1039     Azure, Python    Master's degree  \n",
       "1040              None               None  \n",
       "1041              None               None  \n",
       "1042              None               None  \n",
       "\n",
       "[1043 rows x 4 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.concat([df, df_new], axis=1)\n",
    "\n",
    "df_final = df_final.dropna(subset=['Título'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Excel, Python, R\n",
       "1                Tableau\n",
       "2         Excel, Tableau\n",
       "3                   None\n",
       "4       Excel, Python, R\n",
       "              ...       \n",
       "1038                None\n",
       "1039       Azure, Python\n",
       "1040                None\n",
       "1041                None\n",
       "1042                None\n",
       "Name: Herramientas, Length: 1043, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['Herramientas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Título', 'Puesto', 'sueldo_min', 'sueldo_max', 'Expertise', 'Empresa',\n",
       "       'Modalidad', 'Sector', 'Ubicación', 'Descripción', 'Servicios',\n",
       "       'Otro Idioma', 'EntornoTEC', 'Beneficios', 'Habilidades',\n",
       "       'Herramientas', 'Educación'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Título                 Puesto  \\\n",
      "0                              data analyst           Data Analyst   \n",
      "1             business intelligence analyst  Business Intelligence   \n",
      "2                          research analyst           Data Analyst   \n",
      "3  senior program manager analyst relations           Data Analyst   \n",
      "4                              data analyst           Data Analyst   \n",
      "\n",
      "   sueldo_min  sueldo_max Expertise Empresa Modalidad Sector Ubicación  \\\n",
      "0       50000       70000   Regular     NaN       NaN    NaN    Madrid   \n",
      "1       50000       70000   Regular     NaN       NaN    NaN    Madrid   \n",
      "2       30000       50000   Regular     NaN       NaN    NaN    Madrid   \n",
      "3       50000       70000    Senior     NaN       NaN    NaN    Madrid   \n",
      "4       50000       70000   Regular     NaN       NaN    NaN    Madrid   \n",
      "\n",
      "                                         Descripción  \\\n",
      "0  Una empresa internacional y dinámica busca un ...   \n",
      "1  An innovative edtech company is seeking a Busi...   \n",
      "2  An established industry player is seeking a Re...   \n",
      "3  Join a forward-thinking company at the forefro...   \n",
      "4  Join a forward-thinking company as a Data Anal...   \n",
      "\n",
      "                                           Servicios Otro Idioma EntornoTEC  \\\n",
      "0  ['Tarjeta de restaurante Seguro de salud Segur...         NaN        NaN   \n",
      "1  ['Flexible hybrid work environment Comprehensi...         NaN        NaN   \n",
      "2  ['Competitive benefits Career development oppo...         NaN        NaN   \n",
      "3  ['Equity (Restricted Stock Units)Life Insuranc...         NaN        NaN   \n",
      "4  ['Flexible working hours Health insurance Life...         NaN        NaN   \n",
      "\n",
      "  Beneficios                                Habilidades      Herramientas  \\\n",
      "0        NaN                                        NaN  Excel, Python, R   \n",
      "1        NaN         Análisis de datos, Data governance           Tableau   \n",
      "2        NaN  Análisis de datos, Visualización de datos    Excel, Tableau   \n",
      "3        NaN                                        NaN               NaN   \n",
      "4        NaN  Análisis de datos, Visualización de datos  Excel, Python, R   \n",
      "\n",
      "           Educación  \n",
      "0       Licenciatura  \n",
      "1  Bachelor's degree  \n",
      "2                NaN  \n",
      "3  Bachelor's degree  \n",
      "4  Bachelor's degree  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5s/6q7y_kyj6zl53g0f3jycmzsr0000gn/T/ipykernel_79545/3307121618.py:12: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/5s/6q7y_kyj6zl53g0f3jycmzsr0000gn/T/ipykernel_79545/3307121618.py:13: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/var/folders/5s/6q7y_kyj6zl53g0f3jycmzsr0000gn/T/ipykernel_79545/3307121618.py:14: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_final.to_csv(\"Datos_definitivos.csv\", index = False)\n",
    "# Cargar los datos desde un archivo CSV\n",
    "data = pd.read_csv('Datos_definitivos.csv')\n",
    "\n",
    "# Verificar las primeras filas de los datos\n",
    "print(data.head())\n",
    "\n",
    "# Preparar los datos para el clustering (selecciona las características relevantes)\n",
    "X = data[['Puesto', 'Expertise', 'Sector']]\n",
    "\n",
    "# Convertir variables categóricas a numéricas\n",
    "X['Puesto'] = X['Puesto'].astype('category').cat.codes\n",
    "X['Expertise'] = X['Expertise'].astype('category').cat.codes\n",
    "X['Sector'] = X['Sector'].astype('category').cat.codes\n",
    "\n",
    "# Aplicar K-means para segmentar los datos\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "data['Segmento'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Visualizar la cantidad de ofertas por segmento\n",
    "segment_counts = data['Segmento'].value_counts().reset_index()\n",
    "segment_counts.columns = ['Segmento', 'Cantidad']\n",
    "\n",
    "# Gráfico de barras mostrando la cantidad de ofertas por segmento\n",
    "fig_barras = go.Figure(data=[\n",
    "    go.Bar(x=segment_counts['Segmento'], y=segment_counts['Cantidad'], \n",
    "           marker=dict(color='royalblue'))\n",
    "])\n",
    "\n",
    "# Configurar el layout del gráfico de barras\n",
    "fig_barras.update_layout(\n",
    "    title='Cantidad de Ofertas por Segmento',\n",
    "    xaxis_title='Segmento',\n",
    "    yaxis_title='Cantidad de Ofertas'\n",
    ")\n",
    "\n",
    "# Guardar el gráfico como archivo HTML y abrirlo en el navegador\n",
    "pio.write_html(fig_barras, 'grafico_barras.html')\n",
    "import webbrowser\n",
    "webbrowser.open('grafico_barras.html')\n",
    "\n",
    "# Gráfico de dispersión mostrando los diferentes segmentos\n",
    "fig_dispersion = go.Figure()\n",
    "\n",
    "# Agregar trazas para cada segmento\n",
    "for segmento in data['Segmento'].unique():\n",
    "    seg_data = data[data['Segmento'] == segmento]\n",
    "    fig_dispersion.add_trace(go.Scatter(\n",
    "        x=seg_data['Puesto'], \n",
    "        y=seg_data['Expertise'], \n",
    "        mode='markers',\n",
    "        name=f'Segmento {segmento}',\n",
    "        text=seg_data['Descripción'],  # Mostrar descripción al pasar el ratón\n",
    "        marker=dict(size=10)\n",
    "    ))\n",
    "\n",
    "# Configurar el layout del gráfico de dispersión\n",
    "fig_dispersion.update_layout(\n",
    "    title='Resultados del Análisis de Segmentación',\n",
    "    xaxis_title='Puesto',\n",
    "    yaxis_title='Expertise',\n",
    "    legend_title='Segmentos',\n",
    "    hovermode='closest'\n",
    ")\n",
    "\n",
    "# Guardar el gráfico de dispersión como archivo HTML y abrirlo en el navegador\n",
    "pio.write_html(fig_dispersion, 'grafico_dispersion.html')\n",
    "webbrowser.open('grafico_dispersion.html')\n",
    "# Asegurarte de que el DataFrame tiene los nombres de columnas correctos\n",
    "df_final.columns = [\n",
    "    \"Título\", \"Puesto\", 'sueldo_min','sueldo_max',\"Expertise\", \"Empresa\", \"Modalidad\", \"Sector\", \n",
    "    \"Ubicación\", \"Descripción\", \"Servicios\", \"Otro_Idioma\", \"EntornoTEC\", \n",
    "    \"Beneficios\", \"Habilidades\", \"Herramientas\", \"Educación\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Título', 'Puesto', 'sueldo_min', 'sueldo_max', 'Expertise', 'Empresa',\n",
       "       'Modalidad', 'Sector', 'Ubicación', 'Descripción', 'Servicios',\n",
       "       'Otro_Idioma', 'EntornoTEC', 'Beneficios', 'Habilidades',\n",
       "       'Herramientas', 'Educación'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Título', 'Puesto', 'sueldo_min', 'sueldo_max', 'Expertise', 'Empresa',\n",
      "       'Modalidad', 'Sector', 'Ubicación', 'Descripción', 'Servicios',\n",
      "       'Otro_Idioma', 'EntornoTEC', 'Beneficios', 'Habilidades',\n",
      "       'Herramientas', 'Educación'],\n",
      "      dtype='object')\n",
      "                                     Título                 Puesto Expertise  \\\n",
      "0                              data analyst           Data Analyst   Regular   \n",
      "1             business intelligence analyst  Business Intelligence   Regular   \n",
      "2                          research analyst           Data Analyst   Regular   \n",
      "3  senior program manager analyst relations           Data Analyst    Senior   \n",
      "4                              data analyst           Data Analyst   Regular   \n",
      "\n",
      "  Empresa Modalidad sueldo_min sueldo_max Sector Ubicación  \\\n",
      "0    None      None      50000      70000   None    Madrid   \n",
      "1    None      None      50000      70000   None    Madrid   \n",
      "2    None      None      30000      50000   None    Madrid   \n",
      "3    None      None      50000      70000   None    Madrid   \n",
      "4    None      None      50000      70000   None    Madrid   \n",
      "\n",
      "                                         Descripción  \\\n",
      "0  Una empresa internacional y dinámica busca un ...   \n",
      "1  An innovative edtech company is seeking a Busi...   \n",
      "2  An established industry player is seeking a Re...   \n",
      "3  Join a forward-thinking company at the forefro...   \n",
      "4  Join a forward-thinking company as a Data Anal...   \n",
      "\n",
      "                                           Servicios Otro_Idioma EntornoTEC  \\\n",
      "0  ['Tarjeta de restaurante Seguro de salud Segur...        None       None   \n",
      "1  ['Flexible hybrid work environment Comprehensi...        None       None   \n",
      "2  ['Competitive benefits Career development oppo...        None       None   \n",
      "3  ['Equity (Restricted Stock Units)Life Insuranc...        None       None   \n",
      "4  ['Flexible working hours Health insurance Life...        None       None   \n",
      "\n",
      "  Beneficios                                Habilidades      Herramientas  \\\n",
      "0       None                                       None  Excel, Python, R   \n",
      "1       None         Análisis de datos, Data governance           Tableau   \n",
      "2       None  Análisis de datos, Visualización de datos    Excel, Tableau   \n",
      "3       None                                       None              None   \n",
      "4       None  Análisis de datos, Visualización de datos  Excel, Python, R   \n",
      "\n",
      "           Educación  \n",
      "0       Licenciatura  \n",
      "1  Bachelor's degree  \n",
      "2               None  \n",
      "3  Bachelor's degree  \n",
      "4  Bachelor's degree  \n",
      "                                     Título                 Puesto Expertise  \\\n",
      "0                              data analyst           Data Analyst   Regular   \n",
      "1             business intelligence analyst  Business Intelligence   Regular   \n",
      "2                          research analyst           Data Analyst   Regular   \n",
      "3  senior program manager analyst relations           Data Analyst    Senior   \n",
      "4                              data analyst           Data Analyst   Regular   \n",
      "\n",
      "  Empresa Modalidad sueldo_min sueldo_max Sector Ubicación  \\\n",
      "0    None      None      50000      70000   None    Madrid   \n",
      "1    None      None      50000      70000   None    Madrid   \n",
      "2    None      None      30000      50000   None    Madrid   \n",
      "3    None      None      50000      70000   None    Madrid   \n",
      "4    None      None      50000      70000   None    Madrid   \n",
      "\n",
      "                                         Descripción  \\\n",
      "0  Una empresa internacional y dinámica busca un ...   \n",
      "1  An innovative edtech company is seeking a Busi...   \n",
      "2  An established industry player is seeking a Re...   \n",
      "3  Join a forward-thinking company at the forefro...   \n",
      "4  Join a forward-thinking company as a Data Anal...   \n",
      "\n",
      "                                           Servicios Otro_Idioma EntornoTEC  \\\n",
      "0  ['Tarjeta de restaurante Seguro de salud Segur...        None       None   \n",
      "1  ['Flexible hybrid work environment Comprehensi...        None       None   \n",
      "2  ['Competitive benefits Career development oppo...        None       None   \n",
      "3  ['Equity (Restricted Stock Units)Life Insuranc...        None       None   \n",
      "4  ['Flexible working hours Health insurance Life...        None       None   \n",
      "\n",
      "  Beneficios                                Habilidades      Herramientas  \\\n",
      "0       None                                       None  Excel, Python, R   \n",
      "1       None         Análisis de datos, Data governance           Tableau   \n",
      "2       None  Análisis de datos, Visualización de datos    Excel, Tableau   \n",
      "3       None                                       None              None   \n",
      "4       None  Análisis de datos, Visualización de datos  Excel, Python, R   \n",
      "\n",
      "           Educación  \n",
      "0       Licenciatura  \n",
      "1  Bachelor's degree  \n",
      "2               None  \n",
      "3  Bachelor's degree  \n",
      "4  Bachelor's degree  \n",
      "                                       Título                 Puesto  \\\n",
      "0                                data analyst           Data Analyst   \n",
      "1               business intelligence analyst  Business Intelligence   \n",
      "2                            research analyst           Data Analyst   \n",
      "3    senior program manager analyst relations           Data Analyst   \n",
      "4                                data analyst           Data Analyst   \n",
      "..                                        ...                    ...   \n",
      "341                             data engineer          Data Engineer   \n",
      "342                             data engineer          Data Engineer   \n",
      "343                             data engineer          Data Engineer   \n",
      "344               data analyst 100 presencial           Data Analyst   \n",
      "345                       senior data analyst           Data Analyst   \n",
      "\n",
      "    Expertise Empresa   Modalidad sueldo_min sueldo_max Sector Ubicación  \\\n",
      "0     Regular    None        None      50000      70000   None    Madrid   \n",
      "1     Regular    None        None      50000      70000   None    Madrid   \n",
      "2     Regular    None        None      30000      50000   None    Madrid   \n",
      "3      Senior    None        None      50000      70000   None    Madrid   \n",
      "4     Regular    None        None      50000      70000   None    Madrid   \n",
      "..        ...     ...         ...        ...        ...    ...       ...   \n",
      "341   Regular    None        None      30000      50000   None    Madrid   \n",
      "342   Regular    None        None      30000      50000   None    Madrid   \n",
      "343   Regular    None        None      30000      50000   None    Madrid   \n",
      "344   Regular    None  Presencial      30000      50000   None    Madrid   \n",
      "345    Senior    None        None      50000      70000   None    Madrid   \n",
      "\n",
      "                                           Descripción  \\\n",
      "0    Una empresa internacional y dinámica busca un ...   \n",
      "1    An innovative edtech company is seeking a Busi...   \n",
      "2    An established industry player is seeking a Re...   \n",
      "3    Join a forward-thinking company at the forefro...   \n",
      "4    Join a forward-thinking company as a Data Anal...   \n",
      "..                                                 ...   \n",
      "341  Una innovadora empresa de inteligencia artific...   \n",
      "342  Una empresa de referencia en distribución de m...   \n",
      "343  Una empresa de referencia en distribución de m...   \n",
      "344  Una empresa dinámica en el sector inmobiliario...   \n",
      "345                                    Sin descripción   \n",
      "\n",
      "                                             Servicios Otro_Idioma EntornoTEC  \\\n",
      "0    ['Tarjeta de restaurante Seguro de salud Segur...        None       None   \n",
      "1    ['Flexible hybrid work environment Comprehensi...        None       None   \n",
      "2    ['Competitive benefits Career development oppo...        None       None   \n",
      "3    ['Equity (Restricted Stock Units)Life Insuranc...        None       None   \n",
      "4    ['Flexible working hours Health insurance Life...        None       None   \n",
      "..                                                 ...         ...        ...   \n",
      "341  ['Sueldo competitivo Stock options Flexibilida...        None       None   \n",
      "342  ['Contrato indefinido Teletrabajo 2 días a la ...        None       None   \n",
      "343  ['Contrato indefinido Sistema Flexible e híbri...        None       None   \n",
      "344  [' Análisis de datos Power B I Excel Tableau S...        None       None   \n",
      "345                                                 []        None       None   \n",
      "\n",
      "    Beneficios                                Habilidades  \\\n",
      "0         None                                       None   \n",
      "1         None         Análisis de datos, Data governance   \n",
      "2         None  Análisis de datos, Visualización de datos   \n",
      "3         None                                       None   \n",
      "4         None  Análisis de datos, Visualización de datos   \n",
      "..         ...                                        ...   \n",
      "341       None                                       None   \n",
      "342       None                                       None   \n",
      "343       None                                       None   \n",
      "344       None                                       None   \n",
      "345       None                                       None   \n",
      "\n",
      "               Herramientas          Educación  \n",
      "0          Excel, Python, R       Licenciatura  \n",
      "1                   Tableau  Bachelor's degree  \n",
      "2            Excel, Tableau               None  \n",
      "3                      None  Bachelor's degree  \n",
      "4          Excel, Python, R  Bachelor's degree  \n",
      "..                      ...                ...  \n",
      "341  Docker, Github, Python               None  \n",
      "342                Azure, R               None  \n",
      "343                   Azure               None  \n",
      "344  Excel, Python, Tableau              Grado  \n",
      "345                    None               None  \n",
      "\n",
      "[346 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Conectar a la base de datos SQLite\n",
    "conn = sqlite3.connect('database.db')\n",
    "cursor = conn.cursor()\n",
    "# Eliminamos y creamos la tabla\n",
    "cursor.execute(\"DROP TABLE IF EXISTS bbdd_ofertas\")\n",
    "cursor.execute('''\n",
    "    CREATE TABLE bbdd_ofertas (\n",
    "        Título TEXT,\n",
    "        Puesto TEXT,\n",
    "        Expertise TEXT,\n",
    "        Empresa TEXT,\n",
    "        Modalidad TEXT,\n",
    "        sueldo_min TEXT,\n",
    "        sueldo_max TEXT,\n",
    "        Sector TEXT,\n",
    "        Ubicación TEXT,\n",
    "        Descripción TEXT,\n",
    "        Servicios TEXT,\n",
    "        Otro_Idioma TEXT,\n",
    "        EntornoTEC TEXT,\n",
    "        Beneficios TEXT,\n",
    "        Habilidades TEXT,\n",
    "        Herramientas TEXT,\n",
    "        Educación TEXT\n",
    "    )\n",
    "''')\n",
    "\n",
    "\n",
    "# Asegúrate de que el DataFrame tiene los nombres de columnas correctos\n",
    "print(df_final.columns)  # Verificar los nombres de las columnas\n",
    "\n",
    "# Insertar el DataFrame en la tabla de SQLite\n",
    "df_final.to_sql('bbdd_ofertas', conn, if_exists='append', index=False)\n",
    "\n",
    "# Verificar que los datos se hayan guardado correctamente\n",
    "df_check = pd.read_sql(\"SELECT * FROM bbdd_ofertas LIMIT 5\", conn)\n",
    "print(df_check)\n",
    "\n",
    "# Cerrar la conexión\n",
    "conn.close()\n",
    "\n",
    "\n",
    "# Conectar a la base de datos SQLite\n",
    "conn = sqlite3.connect('database.db')\n",
    "\n",
    "# Leer los datos de la tabla 'job_data' en un DataFrame de pandas\n",
    "query = \"SELECT * FROM bbdd_ofertas LIMIT 5\"\n",
    "df_check = pd.read_sql(query, conn)\n",
    "\n",
    "# Mostrar el DataFrame para verificar que los datos se hayan guardado\n",
    "print(df_check)\n",
    "\n",
    "# Cerrar la conexión\n",
    "conn.close()\n",
    " # Conectar a la base de datos SQLite\n",
    "conn = sqlite3.connect('database.db')\n",
    "\n",
    "# Consultar los datos donde la ubicación es \"Madrid\"\n",
    "query = \"SELECT * FROM bbdd_ofertas WHERE Ubicación = 'Madrid'\"\n",
    "df_madrid = pd.read_sql(query, conn)\n",
    "\n",
    "# Mostrar el DataFrame con los registros de Madrid\n",
    "print(df_madrid)\n",
    "\n",
    "# Cerrar la conexión\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 749 entries, 0 to 1037\n",
      "Data columns (total 17 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   Título        749 non-null    object\n",
      " 1   Puesto        749 non-null    object\n",
      " 2   sueldo_min    749 non-null    int64 \n",
      " 3   sueldo_max    749 non-null    int64 \n",
      " 4   Expertise     749 non-null    object\n",
      " 5   Empresa       16 non-null     object\n",
      " 6   Modalidad     9 non-null      object\n",
      " 7   Sector        70 non-null     object\n",
      " 8   Ubicación     749 non-null    object\n",
      " 9   Descripción   749 non-null    object\n",
      " 10  Servicios     749 non-null    object\n",
      " 11  Otro_Idioma   14 non-null     object\n",
      " 12  EntornoTEC    59 non-null     object\n",
      " 13  Beneficios    46 non-null     object\n",
      " 14  Habilidades   261 non-null    object\n",
      " 15  Herramientas  465 non-null    object\n",
      " 16  Educación     282 non-null    object\n",
      "dtypes: int64(2), object(15)\n",
      "memory usage: 105.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Puesto\n",
       "Data Analyst                 344\n",
       "Data Engineer                146\n",
       "Data Scientist               120\n",
       "Other                         70\n",
       "Data Specialist               19\n",
       "Machine Learning Engineer     19\n",
       "Business Intelligence         11\n",
       "Consultant                     6\n",
       "Data Analytics                 6\n",
       "Data Developer                 4\n",
       "Project Manager                2\n",
       "Data Expert                    1\n",
       "AI Innovation Architect        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['Puesto'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Herramientas\n",
       "Python                                           58\n",
       "Excel                                            57\n",
       "R                                                46\n",
       "Python, R                                        25\n",
       "Python, Tableau                                  21\n",
       "                                                 ..\n",
       "Azure, Docker, Keras, Python, Scikit-learn        1\n",
       "Azure, Docker, Keras, Python, R, Scikit-learn     1\n",
       "Databricks                                        1\n",
       "Docker, Python, R                                 1\n",
       "Docker, Keras, Python, Tensorflow                 1\n",
       "Name: count, Length: 98, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['Herramientas'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
